{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15e24660ead048688e01d147ae29e76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2e64b52576b4c5e95cbed7bd188f204",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4919e73c9fb8484bb05c33b5ba5fe18c",
              "IPY_MODEL_194c80ffeea64b51a165e15bfe62bd90"
            ]
          }
        },
        "b2e64b52576b4c5e95cbed7bd188f204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4919e73c9fb8484bb05c33b5ba5fe18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33be67ffe3d84e6baf5019ca7d4b4ba6",
            "_dom_classes": [],
            "description": " 92%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1248,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1151,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfaae9da3a8c482aa12e815c83609f19"
          }
        },
        "194c80ffeea64b51a165e15bfe62bd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36bcf0ba65a844b586ee3c39b338adb9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1151/1248 [03:11&lt;00:17,  5.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6488c2df53340faa67e06ccabd2ece1"
          }
        },
        "33be67ffe3d84e6baf5019ca7d4b4ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfaae9da3a8c482aa12e815c83609f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36bcf0ba65a844b586ee3c39b338adb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6488c2df53340faa67e06ccabd2ece1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BinhNguyen231/demo_git/blob/master/speech_emotion_recognize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W-ijbq62gNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ded2bf24-6116-418b-ef84-ea7772fe66fd"
      },
      "source": [
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Conv1D, Conv2D,BatchNormalization, MaxPooling1D,MaxPooling2D, LSTM, Dense, Activation, Layer,Reshape\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2UxXup5_ZPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4edb03b-3b00-44fc-d6e5-4fcad7bd73fe"
      },
      "source": [
        "!mkdir audio\n",
        "%cd audio"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/audio\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24kIK25A2mng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "402358ed-3060-4632-84f2-175047cc3d92"
      },
      "source": [
        "!wget https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-14 08:03:01--  https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.117.155\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.117.155|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 208468073 (199M) [application/octet-stream]\n",
            "Saving to: â€˜Audio_Speech_Actors_01-24.zip?download=1â€™\n",
            "\n",
            "Audio_Speech_Actors 100%[===================>] 198.81M  85.6MB/s    in 2.3s    \n",
            "\n",
            "2020-08-14 08:03:04 (85.6 MB/s) - â€˜Audio_Speech_Actors_01-24.zip?download=1â€™ saved [208468073/208468073]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEn3-zXZ2_fa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6493dfc7-5ea2-42fd-bfe8-323308bdff1d"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Audio_Speech_Actors_01-24.zip?download=1'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn7Z-vSL3KNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip Audio_Speech_Actors_01-24.zip?download=1\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3hi_q7G3YMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8da75564-2de6-4e65-cfd4-7b0935bdb1e1"
      },
      "source": [
        "!rm 'Audio_Speech_Actors_01-24.zip?download=1'\n",
        "!ls\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actor_01  Actor_04  Actor_07  Actor_10\tActor_13  Actor_16  Actor_19  Actor_22\n",
            "Actor_02  Actor_05  Actor_08  Actor_11\tActor_14  Actor_17  Actor_20  Actor_23\n",
            "Actor_03  Actor_06  Actor_09  Actor_12\tActor_15  Actor_18  Actor_21  Actor_24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEr8-bx-3ven",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5ff0aa03-bbd9-4982-f5e9-51bd8d8f0a35"
      },
      "source": [
        "data_path = \"./\"\n",
        "dir_list = os.listdir(data_path)\n",
        "\n",
        "dir_list.sort()\n",
        "print(dir_list)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05', 'Actor_06', 'Actor_07', 'Actor_08', 'Actor_09', 'Actor_10', 'Actor_11', 'Actor_12', 'Actor_13', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_20', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_24']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qXojlHa4PYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create DataFrame for Data intel\n",
        "ravdess_db = pd.DataFrame(columns=['path','source','actor', 'gender', 'emotion','emotion_lb'])\n",
        "count = 0\n",
        "dir_list = os.listdir(data_path)\n",
        "dir_list.sort()\n",
        "for i in dir_list:\n",
        "    file_list = os.listdir(data_path + i)\n",
        "    for f in file_list:\n",
        "        nm = f.split('.')[0].split('-')\n",
        "        path = data_path + i + '/' + f\n",
        "        src = int(nm[1])\n",
        "        actor = int(nm[-1])\n",
        "        emotion = int(nm[2])\n",
        "        source = \"Ravdess\"\n",
        "\n",
        "        if int(actor)%2 == 0:\n",
        "            gender = \"female\"\n",
        "        else:\n",
        "            gender = \"male\"\n",
        "\n",
        "        if nm[3] == '01':\n",
        "            intensity = 0\n",
        "        else:\n",
        "            intensity = 1\n",
        "\n",
        "        if nm[4] == '01':\n",
        "            statement = 0\n",
        "        else:\n",
        "            statement = 1\n",
        "\n",
        "        if nm[5] == '01':\n",
        "            repeat = 0\n",
        "        else:\n",
        "            repeat = 1\n",
        "\n",
        "        if emotion == 1:\n",
        "            lb = \"neutral\"\n",
        "        elif emotion == 2:\n",
        "            lb = \"calm\"\n",
        "        elif emotion == 3:\n",
        "            lb = \"happy\"\n",
        "        elif emotion == 4:\n",
        "            lb = \"sad\"\n",
        "        elif emotion == 5:\n",
        "            lb = \"angry\"\n",
        "        elif emotion == 6:\n",
        "            lb = \"fearful\"\n",
        "        elif emotion == 7:\n",
        "            lb = \"disgust\"\n",
        "        elif emotion == 8:\n",
        "            lb = \"surprised\"\n",
        "        else:\n",
        "            lb = \"none\"\n",
        "\n",
        "        ravdess_db.loc[count] = [path,source,actor, gender, emotion,lb]\n",
        "        count += 1\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHDS9TUt5nys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a425d5b8-8030-4a6d-f6c3-4419cdf9466d"
      },
      "source": [
        "ravdess_db.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>source</th>\n",
              "      <th>actor</th>\n",
              "      <th>gender</th>\n",
              "      <th>emotion</th>\n",
              "      <th>emotion_lb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./Actor_01/03-01-01-01-02-01-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./Actor_01/03-01-05-02-02-01-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>5</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./Actor_01/03-01-06-02-02-01-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>6</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./Actor_01/03-01-06-01-01-02-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>6</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./Actor_01/03-01-04-01-02-02-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>4</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  path   source actor gender emotion emotion_lb\n",
              "0  ./Actor_01/03-01-01-01-02-01-01.wav  Ravdess     1   male       1    neutral\n",
              "1  ./Actor_01/03-01-05-02-02-01-01.wav  Ravdess     1   male       5      angry\n",
              "2  ./Actor_01/03-01-06-02-02-01-01.wav  Ravdess     1   male       6    fearful\n",
              "3  ./Actor_01/03-01-06-01-01-02-01.wav  Ravdess     1   male       6    fearful\n",
              "4  ./Actor_01/03-01-04-01-02-02-01.wav  Ravdess     1   male       4        sad"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_7ny8gh6Hyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ravdess_db.to_csv(\"list.csv\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWWIbZ3g6U0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0a95189c-d9a5-4740-c3dd-41fedf01a025"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actor_01  Actor_05  Actor_09  Actor_13\tActor_17  Actor_21  list.csv\n",
            "Actor_02  Actor_06  Actor_10  Actor_14\tActor_18  Actor_22\n",
            "Actor_03  Actor_07  Actor_11  Actor_15\tActor_19  Actor_23\n",
            "Actor_04  Actor_08  Actor_12  Actor_16\tActor_20  Actor_24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JabXaz6j6bYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ravdess_db['split'] =  np.where((ravdess_db.actor ==23) | (ravdess_db.actor ==24), 'Test', \n",
        "                                (np.where((ravdess_db.actor ==21) | (ravdess_db.actor ==22),'Val','Train')))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgiMSrAA6sW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0e00d054-b71f-4baf-c7bc-2b7bcaa92fe2"
      },
      "source": [
        "ravdess_db['split'].value_counts()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Train    1200\n",
              "Test      120\n",
              "Val       120\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueNGL8i76u_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ravdess_db.drop(ravdess_db.index[ravdess_db['emotion_lb'] == 'surprised'], inplace = True)\n",
        "ravdess_db.loc[ravdess_db.emotion_lb=='calm',['emotion','emotion_lb']]= 1,'neutral'"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gbfWHvR7415",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0c5280cd-045a-4e51-f016-1ec8f48b55dc"
      },
      "source": [
        "ravdess_db.emotion_lb.value_counts()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral    288\n",
              "angry      192\n",
              "happy      192\n",
              "disgust    192\n",
              "fearful    192\n",
              "sad        192\n",
              "Name: emotion_lb, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTx_Rs7V76-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_db = ravdess_db.copy()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM-cqGiL8AQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_db.emotion_lb = dataset_db.gender+\"_\"+dataset_db.emotion_lb"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UxLQsX18E0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_db.index=range(len(dataset_db.index))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN3jchjL8GmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_db.to_csv(\"list2.csv\")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRWIMAkS8MK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c3ad8879-881b-48bb-9ba8-7b71c16128e5"
      },
      "source": [
        "dataset_db.emotion_lb.value_counts()\n",
        "dataset_db.sort_values(by=['path'], inplace=True)\n",
        "dataset_db.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>source</th>\n",
              "      <th>actor</th>\n",
              "      <th>gender</th>\n",
              "      <th>emotion</th>\n",
              "      <th>emotion_lb</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>./Actor_01/03-01-01-01-01-01-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>male_neutral</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>./Actor_01/03-01-01-01-01-02-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>male_neutral</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./Actor_01/03-01-01-01-02-01-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>male_neutral</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>./Actor_01/03-01-01-01-02-02-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>male_neutral</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>./Actor_01/03-01-02-01-01-01-01.wav</td>\n",
              "      <td>Ravdess</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>male_neutral</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   path   source  ...    emotion_lb  split\n",
              "10  ./Actor_01/03-01-01-01-01-01-01.wav  Ravdess  ...  male_neutral  Train\n",
              "37  ./Actor_01/03-01-01-01-01-02-01.wav  Ravdess  ...  male_neutral  Train\n",
              "0   ./Actor_01/03-01-01-01-02-01-01.wav  Ravdess  ...  male_neutral  Train\n",
              "6   ./Actor_01/03-01-01-01-02-02-01.wav  Ravdess  ...  male_neutral  Train\n",
              "41  ./Actor_01/03-01-02-01-01-01-01.wav  Ravdess  ...  male_neutral  Train\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zadsv_yj8QHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_db.index = range(len(dataset_db.index))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mCozB0m8awO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56241c14-b65e-4eb0-e5cd-8ba656560f3a"
      },
      "source": [
        "dataset_db.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1248, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeaxQv998dyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "audio_duration = 3\n",
        "sampling_rate = 22050*2\n",
        "input_length = sampling_rate * audio_duration\n",
        "n_mfcc = 20"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waTw_dmF8gWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_sample= np.zeros(input_length)\n",
        "MFCC = librosa.feature.mfcc(data_sample, sr=sampling_rate, n_mfcc=n_mfcc)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0mF7UuB8iDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7be49f0-676a-4a1b-89b4-0d6086399ae7"
      },
      "source": [
        "\n",
        "MFCC.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 259)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09LxrfkG8jzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "47b542ab-a063-46c1-ea32-ffff061f6f5f"
      },
      "source": [
        "dataset_db.split.value_counts()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Train    1040\n",
              "Test      104\n",
              "Val       104\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNG0ckkm8pEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmFspUnX8rkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "15e24660ead048688e01d147ae29e76c",
            "b2e64b52576b4c5e95cbed7bd188f204",
            "4919e73c9fb8484bb05c33b5ba5fe18c",
            "194c80ffeea64b51a165e15bfe62bd90",
            "33be67ffe3d84e6baf5019ca7d4b4ba6",
            "bfaae9da3a8c482aa12e815c83609f19",
            "36bcf0ba65a844b586ee3c39b338adb9",
            "a6488c2df53340faa67e06ccabd2ece1"
          ]
        },
        "outputId": "378699ac-7991-406d-d78b-f2025ccee0dc"
      },
      "source": [
        "audios= np.empty(shape=(dataset_db.shape[0],128, MFCC.shape[1], 1))\n",
        "\n",
        "count=0\n",
        "for i in tqdm(range(len(dataset_db))):\n",
        "    signal, sample_rate = librosa.load(dataset_db.path[i], res_type='kaiser_fast',sr=sampling_rate)\n",
        "    signal,index = librosa.effects.trim(signal,top_db = 25)\n",
        "    signal = scipy.signal.wiener(signal)\n",
        "    \n",
        "    if len(signal) > input_length:\n",
        "        signal = signal[0:input_length]\n",
        "    elif  input_length > len(signal):\n",
        "        max_offset = input_length - len(signal)  \n",
        "        signal = np.pad(signal, (0, max_offset), \"constant\")\n",
        "\n",
        "    melspec = librosa.feature.melspectrogram(signal, sr=sample_rate, n_mels=128,n_fft=2048,hop_length=512)   \n",
        "    logspec = librosa.amplitude_to_db(melspec)\n",
        "    logspec = np.expand_dims(logspec, axis=-1)\n",
        "    audios[count,] = logspec \n",
        "    count+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15e24660ead048688e01d147ae29e76c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1248.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtXdOFxB8t-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = audios[(dataset_db['split'] == 'Train')]\n",
        "y_train = dataset_db.emotion_lb[(dataset_db['split'] == 'Train')]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMobNy1O9N8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f4aa285-4ae3-4dc9-b12e-d44b949eb4bb"
      },
      "source": [
        "print(x_train.shape,y_train.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 128, 259, 1) (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5a9r5L09Pvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7fa0814-db74-4a1f-d48f-ee75c3588fe6"
      },
      "source": [
        "x_test = audios[(dataset_db['split'] == 'Val')]\n",
        "y_test = dataset_db.emotion_lb[(dataset_db['split'] == 'Val')]\n",
        "\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 128, 259, 1) (0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK-h29cM9Vve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a0a6e1a0-a58c-4482-d653-c7814a12d23b"
      },
      "source": [
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ac8b1aeb82b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2666\u001b[0m     \"\"\"\n\u001b[1;32m   2667\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2668\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twKziDnf9Ypc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_traincnn = x_train\n",
        "x_testcnn = x_test\n",
        "x_traincnn.shape,x_testcnn.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyMPGt0e-UMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = len(np.unique(np.argmax(y_train, 1)))\n",
        "input_shape = x_traincnn.shape[1:]\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "#LSTM Configuration\n",
        "num_lstm = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmjn_22u-Uuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS58nzrS-YfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential(name='Audio_CNN_2D')\n",
        "\n",
        "# LFLB1\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=128,kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "# FC\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Model compilation\n",
        "opt = optimizers.Adam(lr=0.001, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqajVgW-fbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oTis0Ne-hDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train Config\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "mcp_save = ModelCheckpoint('Audio_2DCNN_4L.h5', save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=batch_size, epochs=num_epochs,validation_data=(x_testcnn, y_test), callbacks=[mcp_save, lr_reduce])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-xH2K2N-mkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}